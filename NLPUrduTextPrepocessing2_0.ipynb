{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Wjy2w9rxmOEevKboke1d7eJLQlnQlHj8",
      "authorship_tag": "ABX9TyP+aesB35u6GO7dSiy05Jde",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SheikhMudassarHanif/NLP/blob/main/NLPUrduTextPrepocessing2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "phase3 starting"
      ],
      "metadata": {
        "id": "2pGgV0Fhchaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "\n"
      ],
      "metadata": {
        "id": "NNOleLYZcpqk"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk as nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA4TRSsNLGVx",
        "outputId": "ad240ec6-e6f8-42bc-d82b-50082b822168"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/urdu_sarcastic_dataset.csv')\n",
        "df.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4','Unnamed: 5','Unnamed: 6','Unnamed: 7'],inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zyj4abxw-dO_",
        "outputId": "8acae53e-49d0-4e2f-a130-fde629dc20bd"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           urdu_text  is_sarcastic\n",
              "0  ğŸ¤£ğŸ˜‚ğŸ˜‚ ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†Û...           1.0\n",
              "1  Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...           1.0\n",
              "2  Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...           0.0\n",
              "3                                       Ù†ÛÛŒÚº Ù¾Ø§Ø¦ÛŒÙ† ğŸ˜           0.0\n",
              "4   `` Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ...           1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8bdbe2b9-06c8-4cf0-a1f1-52b9e97d90cd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>urdu_text</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ğŸ¤£ğŸ˜‚ğŸ˜‚ ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†Û...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ù†ÛÛŒÚº Ù¾Ø§Ø¦ÛŒÙ† ğŸ˜</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>`` Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8bdbe2b9-06c8-4cf0-a1f1-52b9e97d90cd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8bdbe2b9-06c8-4cf0-a1f1-52b9e97d90cd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8bdbe2b9-06c8-4cf0-a1f1-52b9e97d90cd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-525c01e9-c27b-4933-a1ec-e635056b6610\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-525c01e9-c27b-4933-a1ec-e635056b6610')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-525c01e9-c27b-4933-a1ec-e635056b6610 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 19955,\n  \"fields\": [\n    {\n      \"column\": \"urdu_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15813,\n        \"samples\": [\n          \"\\u0635\\u0644\\u06cc \\u0627\\u0644\\u0644\\u06c1 \\u0639\\u0644\\u06cc\\u06c1 \\u0648\\u0627\\u0670\\u0644\\u06c1 \\u0648\\u0633\\u0644\\u0645\",\n          \"\\u0633\\u0686\\u06cc \\u0645\\u0632\\u06c1 \\u0622\\u06cc\\u0627 \\u06d4\\u06d4\\u06d4\\u0648\\u06cc\\u0633\\u06d2 \\u062d\\u06cc\\u062f\\u0631 \\u0628\\u06be\\u0627\\u0626\\u06cc \\u0628\\u06c1\\u062a \\u067e\\u06cc\\u0627\\u0631\\u06d2 \\u0627\\u0646\\u0633\\u0627\\u0646 \\u06c1\\u06cc\\u06ba \\u2764\",\n          \"\\ud83d\\ude02\\ud83e\\udd23\\ud83d\\ude02\\u0622\\u067e \\u0633\\u06d2 \\u0628\\u06c1\\u062a \\u0639\\u0631\\u0635\\u06c1 \\u067e\\u06c1\\u0644\\u06d2 \\u06a9\\u06c1\\u0627 \\u062a\\u06be\\u0627 \\u06a9\\u06c1 \\u0686\\u06be\\u0648\\u0644\\u06d2 \\u0641\\u0631\\u0648\\u0634 \\u0636\\u0645\\u06cc\\u0631 \\u0641\\u0631\\u0648\\u0634 \\u0627\\u0648\\u0631 \\u0633\\u067e\\u0644\\u0627\\u0626\\u06cc\\u0631 \\u062e\\u0648\\u062f \\u0633\\u0627\\u062e\\u062a\\u06c1 \\u0635\\u062d\\u0627\\u0641\\u06cc \\u06c1\\u06d2 \\u06cc\\u06c1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_sarcastic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5000119253068661,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus=df['urdu_text'].to_numpy()"
      ],
      "metadata": {
        "id": "2SjpZCKX-dtR"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def remove_stopWords(whitespaced_tokens, numpy_array):\n",
        "    # Create a new list to hold tokens after removing stop words\n",
        "    filtered_tokens = []\n",
        "\n",
        "    for word in whitespaced_tokens:\n",
        "        if word not in numpy_array:\n",
        "            filtered_tokens.append(word)  # Keep the word if it's not a stop word\n",
        "\n",
        "    return filtered_tokens"
      ],
      "metadata": {
        "id": "-B6zDXpvhcIM"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def remove_punctuation(text):\n",
        "#     return text.translate(str.maketrans('', '', string.punctuation))\n",
        "def remove_urdu_punctuation(text):\n",
        "    urdu_punctuation = r\"[Û”.ØŒØ›ØŸ!''\\\"â€â€œ():{}<>[\\]|/\\\\~`@#$%^&*+=-]\"\n",
        "    return re.sub(urdu_punctuation, \"\", text)"
      ],
      "metadata": {
        "id": "mv_4C_VhmQUj"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_hashtags(text):\n",
        "\n",
        "  return re.sub(r'#\\w+', '', text)\n"
      ],
      "metadata": {
        "id": "tQr1D8gO1ESK"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def remove_url(text):\n",
        "    return re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)"
      ],
      "metadata": {
        "id": "I6eZz0lEzECR"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: remove emjoi funcion\n",
        "\n",
        "import re\n",
        "\n",
        "def remove_emoji(text):\n",
        "  emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "  return emoji_pattern.sub(r'', text)\n"
      ],
      "metadata": {
        "id": "jU3fzlD0DV9H"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Remove_short_convos(text):\n",
        "  positive_sentiments = [\"Ø®ÙˆØ´ÛŒ\", \"Ù…Ø­Ø¨Øª\", \"Ø§Ù…ÛŒØ¯\", \"Ø¹Ø²Øª\", \"Ø§Ø·Ù…ÛŒÙ†Ø§Ù†\", \"Ø±Ø­Ù…Øª\", \"Ø®ÙˆØ§Ø¨\", \"Ù…Ø³Ø±Øª\", \"Ú©Ø§Ù…ÛŒØ§Ø¨ÛŒ\", \"Ø³Ú©ÙˆÙ†\", \"Ø´Ú©Ø±ÛŒÛ\", \"Ø¯ÙˆØ³ØªÛŒ\", \"Ø®ÙˆØ¨ØµÙˆØ±ØªÛŒ\", \"Ù‚ÙˆØª\", \"Ø®ÛŒØ±Ø®ÙˆØ§ÛÛŒ\"]\n",
        "  negative_sentiments = [\"ØºÙ…\", \"Ù†ÙØ±Øª\", \"Ù…Ø§ÛŒÙˆØ³ÛŒ\", \"Ø´Ø±Ù…Ù†Ø¯Ú¯ÛŒ\", \"Ø®ÙˆÙ\", \"ØªÙ†ÛØ§Ø¦ÛŒ\", \"Ø¯Ú©Ú¾\", \"Ù†Ø§Ú©Ø§Ù…ÛŒ\", \"Ù¾Ø±ÛŒØ´Ø§Ù†ÛŒ\", \"Ø¯Ú¾Ù…Ú©ÛŒ\", \"Ù†ÙØ±Øª\", \"Ø®Ø·Ø±Û\", \"Ø¨Û’ Ú†ÛŒÙ†ÛŒ\", \"Ø¯Ú¾ÙˆÚ©Û\", \"ØºØµÛ\"]\n",
        "  if any(sentiment in text for sentiment in positive_sentiments) and any(sentiment in text for sentiment in negative_sentiments):\n",
        "    return True\n",
        "  else:\n",
        "    return False\n"
      ],
      "metadata": {
        "id": "D41F7aozyzFF"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from LughaatNLP import LughaatNLP\n",
        "urdu_text_processing = LughaatNLP()\n"
      ],
      "metadata": {
        "id": "5Q5hR1mNxxaD"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text, stopwords_array):\n",
        "    # Step 1: Remove URLs\n",
        "    text = remove_url(text)\n",
        "\n",
        "    # Step 2: Remove Hashtags\n",
        "    text = remove_hashtags(text)\n",
        "\n",
        "    #step2.5 : Remove Emjoi\n",
        "    text=remove_emoji(text)\n",
        "    #step2.6:normalize\n",
        "    text=urdu_text_processing.normalize(text)\n",
        "\n",
        "    # Step 3: Remove Punctuation\n",
        "    text = remove_urdu_punctuation(text)\n",
        "\n",
        "    # Step 4: Tokenize text\n",
        "    # whitespaced_tokens = text.split()\n",
        "    whitespaced_tokens=nltk.word_tokenize(text)\n",
        "\n",
        "    # Step 5: Remove Stopwords\n",
        "    filtered_tokens = remove_stopWords(whitespaced_tokens, stopwords_array)\n",
        "\n",
        "    return ' '.join(filtered_tokens)\n",
        "\n",
        "\n",
        "\n",
        "data=pd.read_csv('/content/drive/MyDrive/stopwords-list.csv')\n",
        "df = pd.DataFrame(data)\n",
        "urdu_stopwords = df.to_numpy()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cleaned_corpus=[]\n",
        "for doc in corpus:\n",
        "  words = doc.split()\n",
        "  if len(words)<=3:\n",
        "    if Remove_short_convos(doc):\n",
        "      cleaned_corpus.append(clean_text(doc,urdu_stopwords))\n",
        "\n",
        "  else:\n",
        "      cleaned_corpus.append(clean_text(doc,urdu_stopwords))\n",
        "\n",
        "\n",
        "\n",
        "#cleaned corpus\n",
        "cleaned_corpus\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5akeACpjPGV",
        "outputId": "b26eeba4-f0f8-4d55-afa3-f71f8b32893c"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ú©ØªØ§Ø¨ Ø¯Ù„Ú†Ø³Ù¾ Ù¾Ø³Ù†Ø¯',\n",
              " 'Ø²Ù†Ø¯Ú¯ÛŒ Ú©Ø§Ù…ÛŒØ§Ø¨ÛŒ Ù…Ø­Ù†Øª ØµØ¨Ø± Ø¶Ø±ÙˆØ±ÛŒ',\n",
              " 'Ú©Ø§Ù… Ø®ØªÙ…',\n",
              " 'Ø­Ú©ÙˆÙ…Øª Ù…Ø­Ù†Øª Ú©Ø§Ù…ÛŒØ§Ø¨ÛŒ Ø­Ø§ØµÙ„',\n",
              " 'Ø³ÛŒØ§Ø³ØªØ¯Ø§Ù†ÙˆÚº Ø¹ÙˆØ§Ù… Ø³Ø®Øª Ù‚ÙˆØ§Ù†ÛŒÙ† Ø¨Ù†Ø§Ø¦Û’',\n",
              " 'Ø¨Ú†Û’ Ø±ÙˆØ²Ø§Ù†Û Ú©ØªØ§Ø¨ÛŒÚº Ù¾Ú‘Ú¾ØªÛ’ Ú©Ø§Ù…ÛŒØ§Ø¨',\n",
              " 'Ø·Ù„Ø¨Ø§Ø¡ Ø³ÛŒØ§Ø³Øª Ø¨Ø§Øª Ú©ØªØ§Ø¨ÛŒÚº Ù¾Ú‘Ú¾ØªÛ’']"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_words = {\n",
        "    # General Nouns\n",
        "    'Ú©ØªØ§Ø¨': ['Ú©ØªØ§Ø¨', 'Ú©ØªØ§Ø¨ÛŒÚº'],                     # Book\n",
        "    'Ú¯Ú¾Ø±': ['Ú¯Ú¾Ø±', 'Ú¯Ú¾Ø±ÙˆÚº'],                         # House\n",
        "    'Ø¨Ú†Û': ['Ø¨Ú†Û', 'Ø¨Ú†Û’', 'Ø¨Ú†ÙˆÚº'],                   # Child\n",
        "    'Ù†Ø¸Ø§Ù…': ['Ù†Ø¸Ø§Ù…', 'Ù†Ø¸Ø§Ù…ÙˆÚº'],                     # System\n",
        "    'Ø¯Ù†ÛŒØ§': ['Ø¯Ù†ÛŒØ§', 'Ø¯Ù†ÛŒØ§ÙˆÚº'],                      # World\n",
        "    'Ø®ÙˆØ§Ø¨': ['Ø®ÙˆØ§Ø¨', 'Ø®ÙˆØ§Ø¨ÙˆÚº'],                      # Dream\n",
        "    'Ø¯ÙˆØ³Øª': ['Ø¯ÙˆØ³Øª', 'Ø¯ÙˆØ³ØªÙˆÚº'],                      # Friend\n",
        "    'Ù…Ø­Ø¨Øª': ['Ù…Ø­Ø¨Øª', 'Ù…Ø­Ø¨ØªÙˆÚº'],                      # Love\n",
        "    'Ø®ÙˆØ´ÛŒ': ['Ø®ÙˆØ´ÛŒ', 'Ø®ÙˆØ´ÛŒÙˆÚº'],                      # Happiness\n",
        "    'Ø¯Ú©Ú¾': ['Ø¯Ú©Ú¾', 'Ø¯Ú©Ú¾ÙˆÚº'],                          # Sadness\n",
        "    'ÙØ·Ø±Øª': ['ÙØ·Ø±Øª', 'ÙØ·Ø±ØªÙˆÚº'],                      # Nature\n",
        "    'Ú©Ø§Ù…': ['Ú©Ø§Ù…', 'Ú©Ø§Ù…ÙˆÚº'],                        # Work\n",
        "\n",
        "    # General Adjectives\n",
        "    'Ø®ÙˆØ¨ØµÙˆØ±Øª': ['Ø®ÙˆØ¨ØµÙˆØ±Øª', 'Ø®ÙˆØ¨ØµÙˆØ±ØªÙˆÚº'],          # Beautiful\n",
        "    'Ø§Ú†Ú¾Ø§': ['Ø§Ú†Ú¾Ø§', 'Ø§Ú†Ú¾ÛŒ', 'Ø§Ú†Ú¾Û’'],                # Good\n",
        "    'Ø¨Ú‘Ø§': ['Ø¨Ú‘Ø§', 'Ø¨Ú‘ÛŒ', 'Ø¨Ú‘Û’'],                    # Big\n",
        "    'Ú†Ú¾ÙˆÙ¹Ø§': ['Ú†Ú¾ÙˆÙ¹Ø§', 'Ú†Ú¾ÙˆÙ¹ÛŒ', 'Ú†Ú¾ÙˆÙ¹Û’'],           # Small\n",
        "    'Ù…ÛÙ†Ú¯Ø§': ['Ù…ÛÙ†Ú¯Ø§', 'Ù…ÛÙ†Ú¯ÛŒ', 'Ù…ÛÙ†Ú¯Û’'],            # Expensive\n",
        "    'Ø³Ø³ØªØ§': ['Ø³Ø³ØªØ§', 'Ø³Ø³ØªÛŒ', 'Ø³Ø³ØªÛ’'],               # Cheap\n",
        "    'Ø³Ø®Øª': ['Ø³Ø®Øª', 'Ø³Ø®ØªÛŒ', 'Ø³Ø®ØªÛŒÙˆÚº'],               # Hard\n",
        "\n",
        "    # General Verbs\n",
        "    'Ù¾Ú‘Ú¾Ù†Ø§': ['Ù¾Ú‘Ú¾Ù†Ø§', 'Ù¾Ú‘Ú¾ØªÛ’', 'Ù¾Ú‘Ú¾ØªÛŒ', 'Ù¾Ú‘Ú¾Ø§'],   # To read\n",
        "    'Ù„Ú©Ú¾Ù†Ø§': ['Ù„Ú©Ú¾Ù†Ø§', 'Ù„Ú©Ú¾ØªÛ’', 'Ù„Ú©Ú¾ØªÛŒ', 'Ù„Ú©Ú¾Ø§'],    # To write\n",
        "    'Ú†Ù„Ù†Ø§': ['Ú†Ù„Ù†Ø§', 'Ú†Ù„ØªÛ’', 'Ú†Ù„ØªÛŒ', 'Ú†Ù„Ø§'],          # To walk\n",
        "    'Ø¯ÛŒÚ©Ú¾Ù†Ø§': ['Ø¯ÛŒÚ©Ú¾Ù†Ø§', 'Ø¯ÛŒÚ©Ú¾ØªÛ’', 'Ø¯ÛŒÚ©Ú¾ØªÛŒ', 'Ø¯ÛŒÚ©Ú¾Ø§'], # To see\n",
        "    'Ø³Ù†Ø§': ['Ø³Ù†Ø§', 'Ø³Ù†ØªÛ’', 'Ø³Ù†Ø§Ø¦ÛŒ', 'Ø³Ù†Ø§ÛŒØ§'],         # To hear\n",
        "    'Ø³Ù…Ø¬Ú¾Ù†Ø§': ['Ø³Ù…Ø¬Ú¾Ù†Ø§', 'Ø³Ù…Ø¬Ú¾ØªÛ’', 'Ø³Ù…Ø¬Ú¾ØªÛŒ', 'Ø³Ù…Ø¬Ú¾Ø§'], # To understand\n",
        "    'Ú©Ú¾ÛŒÙ„Ù†Ø§': ['Ú©Ú¾ÛŒÙ„Ù†Ø§', 'Ú©Ú¾ÛŒÙ„ØªÛ’', 'Ú©Ú¾ÛŒÙ„ØªÛŒ', 'Ú©Ú¾ÛŒÙ„Ø§'], # To play\n",
        "    'Ú©Ú¾Ø§Ù†Ø§': ['Ú©Ú¾Ø§Ù†Ø§', 'Ú©Ú¾Ø§ØªÛ’', 'Ú©Ú¾Ø§ØªÛŒ', 'Ú©Ú¾Ø§ÛŒØ§'],     # To eat\n",
        "\n",
        "    # Political Nouns\n",
        "    'Ø³ÛŒØ§Ø³Øª': ['Ø³ÛŒØ§Ø³Øª', 'Ø³ÛŒØ§Ø³ØªØ¯Ø§Ù†', 'Ø³ÛŒØ§Ø³ØªØ¯Ø§Ù†ÙˆÚº'],    # Politics, Politician\n",
        "    'Ø­Ú©ÙˆÙ…Øª': ['Ø­Ú©ÙˆÙ…Øª', 'Ø­Ú©ÙˆÙ…ØªÛŒÚº'],                     # Government\n",
        "    'Ù¾Ø§Ø±Ù¹ÛŒ': ['Ù¾Ø§Ø±Ù¹ÛŒ', 'Ù¾Ø§Ø±Ù¹ÛŒØ§Úº'],                      # Party\n",
        "    'Ø§Ù†ØªØ®Ø§Ø¨Ø§Øª': ['Ø§Ù†ØªØ®Ø§Ø¨Ø§Øª', 'Ø§Ù†ØªØ®Ø§Ø¨ÛŒ'],              # Elections\n",
        "    'Ø­Ø²Ø¨': ['Ø­Ø²Ø¨', 'Ø§Ø­Ø²Ø§Ø¨'],                           # Party (political)\n",
        "    'Ù‚ÙˆÙ…ÛŒ': ['Ù‚ÙˆÙ…ÛŒ', 'Ù‚ÙˆÙ…ÛŒØª'],                         # National\n",
        "    'Ù…Ø³Ø¦Ù„Û': ['Ù…Ø³Ø¦Ù„Û', 'Ù…Ø³Ø§Ø¦Ù„'],                       # Issue\n",
        "    'Ø¨Ø¬Ù¹': ['Ø¨Ø¬Ù¹', 'Ø¨Ø¬Ù¹ÙˆÚº'],                           # Budget\n",
        "    'Ù…ÙØ§ÛÙ…Øª': ['Ù…ÙØ§ÛÙ…Øª', 'Ù…ÙØ§ÛÙ…ØªÛŒÚº'],                 # Reconciliation\n",
        "    'Ù¾Ø§Ù„ÛŒØ³ÛŒ': ['Ù¾Ø§Ù„ÛŒØ³ÛŒ', 'Ù¾Ø§Ù„ÛŒØ³ÛŒÙˆÚº'],                 # Policy\n",
        "    'ØºÛŒØ±Øª': ['ØºÛŒØ±Øª', 'ØºÛŒØ±ØªÛŒÚº'],                       # Honor\n",
        "    'Ø¯ÙˆÙ„Øª': ['Ø¯ÙˆÙ„Øª', 'Ø¯ÙˆÙ„ØªÛŒÚº'],                       # Wealth\n",
        "    'Ù‚Ø§Ù†ÙˆÙ†': ['Ù‚Ø§Ù†ÙˆÙ†', 'Ù‚ÙˆØ§Ù†ÛŒÙ†'],                     # Law\n",
        "    'Ø§Ù…Ù†': ['Ø§Ù…Ù†', 'Ø§Ù…Ù†ÛŒÚº'],                          # Peace\n",
        "    'ØªÙ†Ù‚ÛŒØ¯': ['ØªÙ†Ù‚ÛŒØ¯', 'ØªÙ†Ù‚ÛŒØ¯ÛŒÚº'],                     # Criticism\n",
        "\n",
        "    # Sarcastic Expressions\n",
        "    'ÙˆØ§Û': ['ÙˆØ§Û', 'ÙˆØ§Û ÙˆØ§Û'],                       # Wow\n",
        "    'Ø¨ÛØª Ø§Ú†Ú¾Ø§': ['Ø¨ÛØª Ø§Ú†Ú¾Ø§', 'Ø¨ÛØª Ø§Ú†Ú¾ÛŒ', 'Ø¨ÛØª Ø§Ú†Ú¾Û’'], # Very good (sarcastic)\n",
        "    'Ú©Ù…Ø§Ù„': ['Ú©Ù…Ø§Ù„', 'Ú©Ù…Ø§Ù„Ø§Øª'],                      # Amazing (sarcastic)\n",
        "    'Ø¹Ù…Ø¯Û': ['Ø¹Ù…Ø¯Û', 'Ø¹Ù…Ø¯Û Ú©Ø§Ù…'],                     # Excellent (sarcastic)\n",
        "    'Ú©ÛŒØ§ Ø¨Ø§Øª ÛÛ’': ['Ú©ÛŒØ§ Ø¨Ø§Øª ÛÛ’', 'Ú©ÛŒØ§ Ø¨Ø§ØªÛŒÚº ÛÛŒÚº'],     # What a thing (sarcastic)\n",
        "    'Ø²Ø¨Ø±Ø¯Ø³Øª': ['Ø²Ø¨Ø±Ø¯Ø³Øª', 'Ø²Ø¨Ø±Ø¯Ø³ØªÛŒ'],                 # Fantastic (sarcastic)\n",
        "    'Ù…Ø²Ø§ Ø¢ Ú¯ÛŒØ§': ['Ù…Ø²Ø§ Ø¢ Ú¯ÛŒØ§', 'Ù…Ø²Ø§ Ø¢Ú¯ÛŒØ§'],          # That was fun (sarcastic)\n",
        "    'Ø´Ú©Ø±ÛŒÛ': ['Ø´Ú©Ø±ÛŒÛ', 'Ø´Ú©Ø±ÛŒÛ Ø§Ø¯Ø§ Ú©Ø±Ù†Ø§'],             # Thank you (can be sarcastic)\n",
        "\n",
        "    # Political Adjectives\n",
        "    'Ø³ÛŒØ§Ø³ÛŒ': ['Ø³ÛŒØ§Ø³ÛŒ', 'Ø³ÛŒØ§Ø³ÛŒÙˆÚº'],                    # Political\n",
        "    'Ù…Ù‚Ø§Ù…ÛŒ': ['Ù…Ù‚Ø§Ù…ÛŒ', 'Ù…Ù‚Ø§Ù…ÛŒÙˆÚº'],                    # Local\n",
        "    'Ø¹Ù„Ø§Ù‚Ø§Ø¦ÛŒ': ['Ø¹Ù„Ø§Ù‚Ø§Ø¦ÛŒ', 'Ø¹Ù„Ø§Ù‚Ø§Ø¦ÛŒÙˆÚº'],              # Regional\n",
        "    'Ù…ÙÛÙˆÙ…ÛŒ': ['Ù…ÙÛÙˆÙ…ÛŒ', 'Ù…ÙÛÙˆÙ…ÛŒÙˆÚº'],                  # Conceptual\n",
        "    'Ù…ÙØ§ÛÙ…ØªÛŒ': ['Ù…ÙØ§ÛÙ…ØªÛŒ', 'Ù…ÙØ§ÛÙ…ØªÛŒÙˆÚº'],              # Reconciliatory\n",
        "    'Ù…ÙÛŒØ¯': ['Ù…ÙÛŒØ¯', 'Ù…ÙÛŒØ¯ÙˆÚº'],                        # Useful\n",
        "    'Ù†ÛŒÚ©': ['Ù†ÛŒÚ©', 'Ù†ÛŒÚ©ÙˆÚº'],                            # Good/virtuous\n",
        "\n",
        "    # Political Verbs\n",
        "    'Ú†Ù†Ù†Ø§': ['Ú†Ù†Ù†Ø§', 'Ú†Ù†ØªÛ’', 'Ú†Ù†ØªÛŒ', 'Ú†Ù†Ø§'],            # To elect\n",
        "    'Ø¨ÛŒØ§Ù† Ú©Ø±Ù†Ø§': ['Ø¨ÛŒØ§Ù† Ú©Ø±Ù†Ø§', 'Ø¨ÛŒØ§Ù† Ú©Ø±ØªÛ’', 'Ø¨ÛŒØ§Ù† Ú©Ø±ØªÛŒ'], # To state\n",
        "    'Ù…Ø°Ø§Ú©Ø±Û Ú©Ø±Ù†Ø§': ['Ù…Ø°Ø§Ú©Ø±Û Ú©Ø±Ù†Ø§', 'Ù…Ø°Ø§Ú©Ø±Û’ Ú©Ø±ØªÛ’'],    # To negotiate\n",
        "    'Ù…Ù†Ø¸ÙˆØ± Ú©Ø±Ù†Ø§': ['Ù…Ù†Ø¸ÙˆØ± Ú©Ø±Ù†Ø§', 'Ù…Ù†Ø¸ÙˆØ± Ú©Ø±ØªÛ’'],       # To approve\n",
        "    'ØªØ­Ø±ÛŒÚ© Ú©Ø±Ù†Ø§': ['ØªØ­Ø±ÛŒÚ© Ú©Ø±Ù†Ø§', 'ØªØ­Ø±ÛŒÚ© Ú©Ø±ØªÛ’'],       # To motivate\n",
        "    'Ø§Ø¬Ù„Ø§Ø³ Ú©Ø±Ù†Ø§': ['Ø§Ø¬Ù„Ø§Ø³ Ú©Ø±Ù†Ø§', 'Ø§Ø¬Ù„Ø§Ø³ Ú©Ø±ØªÛ’'],       # To convene\n",
        "    'ØªÙ†Ù‚ÛŒØ¯ Ú©Ø±Ù†Ø§': ['ØªÙ†Ù‚ÛŒØ¯ Ú©Ø±Ù†Ø§', 'ØªÙ†Ù‚ÛŒØ¯ Ú©Ø±ØªÛ’'],        # To criticize\n",
        "    'ØªØ´Ú©ÛŒÙ„ Ø¯ÛŒÙ†Ø§': ['ØªØ´Ú©ÛŒÙ„ Ø¯ÛŒÙ†Ø§', 'ØªØ´Ú©ÛŒÙ„ Ø¯ÛŒØªÛ’'],        # To form\n",
        "\n",
        "    # Other\n",
        "    'Ù…Ø³Ù„Ù…': ['Ù…Ø³Ù„Ù…', 'Ù…Ø³Ù„Ù…Ø§Ù†', 'Ù…Ø³Ù„Ù…Ø§Ù†ÙˆÚº'],            # Muslim\n",
        "    'Ø¹ÙˆØ§Ù…': ['Ø¹ÙˆØ§Ù…', 'Ø¹ÙˆØ§Ù…ÛŒ'],                          # Public\n",
        "    'Ø¹Ù‚ÛŒØ¯Û': ['Ø¹Ù‚ÛŒØ¯Û', 'Ø¹Ù‚Ø§Ø¦Ø¯'],                       # Belief\n",
        "}\n",
        "\n",
        "# Example usage\n",
        "\n"
      ],
      "metadata": {
        "id": "1CdMIphMBJd2"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now lemmatization"
      ],
      "metadata": {
        "id": "AC0kFYg1DQ9_"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "updated_corpus = []\n",
        "\n",
        "for sentence in cleaned_corpus:\n",
        "    updated_sentence = []\n",
        "    words = sentence.split()  # Split sentence into individual words\n",
        "    for word in words:\n",
        "        found_root = False\n",
        "        for root_word, variants in base_words.items():\n",
        "            if word in variants:\n",
        "                updated_sentence.append(root_word)\n",
        "                found_root = True\n",
        "                break\n",
        "        if not found_root:\n",
        "            updated_sentence.append(word)  # If no root found, keep the original word\n",
        "    updated_corpus.append(' '.join(updated_sentence))\n",
        "\n",
        "# Print the updated corpus with root words\n",
        "for sentence in updated_corpus:\n",
        "    print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vPcEnGELd9o",
        "outputId": "3525dd13-76ba-47e2-a94d-3bb7b77e91e4"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ú©ØªØ§Ø¨ Ø¯Ù„Ú†Ø³Ù¾ Ù¾Ø³Ù†Ø¯\n",
            "Ø²Ù†Ø¯Ú¯ÛŒ Ú©Ø§Ù…ÛŒØ§Ø¨ÛŒ Ù…Ø­Ù†Øª ØµØ¨Ø± Ø¶Ø±ÙˆØ±ÛŒ\n",
            "Ú©Ø§Ù… Ø®ØªÙ…\n",
            "Ø­Ú©ÙˆÙ…Øª Ù…Ø­Ù†Øª Ú©Ø§Ù…ÛŒØ§Ø¨ÛŒ Ø­Ø§ØµÙ„\n",
            "Ø³ÛŒØ§Ø³Øª Ø¹ÙˆØ§Ù… Ø³Ø®Øª Ù‚Ø§Ù†ÙˆÙ† Ø¨Ù†Ø§Ø¦Û’\n",
            "Ø¨Ú†Û Ø±ÙˆØ²Ø§Ù†Û Ú©ØªØ§Ø¨ Ù¾Ú‘Ú¾Ù†Ø§ Ú©Ø§Ù…ÛŒØ§Ø¨\n",
            "Ø·Ù„Ø¨Ø§Ø¡ Ø³ÛŒØ§Ø³Øª Ø¨Ø§Øª Ú©ØªØ§Ø¨ Ù¾Ú‘Ú¾Ù†Ø§\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install LughaatNLP\n",
        "from LughaatNLP import LughaatNLP"
      ],
      "metadata": {
        "id": "M7Hun_5_5Sdw"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urdu_text_processing = LughaatNLP()\n"
      ],
      "metadata": {
        "id": "TJPFVFhSAB6-"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmed_sentence=[]\n",
        "\n",
        "for sentence in cleaned_corpus:\n",
        "  stemmed_sentence.append(urdu_text_processing.urdu_stemmer(sentence))\n"
      ],
      "metadata": {
        "id": "gl1Jh7RVBXaY"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in stemmed_sentence:\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mkLCNK8BsqZ",
        "outputId": "1bef3a88-77ed-4e14-9cec-8f6c15a6ee52"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ú©ØªØ¨ Ø¯Ù„Ú†Ø³Ù¾ Ù¾Ø³Ù†Ø¯\n",
            "Ø²Ù†Ø¯Ú¯ÛŒ Ú©Ø§Ù…ÛŒØ§Ø¨ÛŒ Ù…Ø­Ù†Øª ØµØ¨Ø± Ø¶Ø±ÙˆØ±ÛŒ\n",
            "Ú©Ø§Ù… Ø®ØªÙ…\n",
            "Ø­Ú©ÙˆÙ…Øª Ù…Ø­Ù†Øª Ú©Ø§Ù…ÛŒØ§Ø¨ÛŒ Ø­Ø§ØµÙ„\n",
            "Ø³ÛŒØ§Ø³ØªØ¯Ø§Ù†Ø§ Ø¹ÙˆØ§Ù… Ø³Ø®Øª Ù‚ÙˆØ§Ù†ÛŒÙ† Ø¨Ù†Ø§Ø¦Û\n",
            "Ø¨Ú†Û Ø±ÙˆØ²Ø§Ù†Û Ú©ØªØ¨ Ù¾Ú‘Ú¾ Ú©Ø§Ù…ÛŒØ§Ø¨\n",
            "Ø·Ù„Ø¨Ø¡ Ø³ÛŒØ§Ø³Øª Ø¨Ù‡ Ú©ØªØ¨ Ù¾Ú‘Ú¾\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phase 3 start feature extraction"
      ],
      "metadata": {
        "id": "T4NHmIv7DQm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenization step 1\n",
        "vocabulary=[]\n",
        "for sentence in updated_corpus:\n",
        "  words=sentence.split()\n",
        "  for word in words:\n",
        "    if word not in vocabulary:\n",
        "      vocabulary.append(word)"
      ],
      "metadata": {
        "id": "kt5bHHyeB4Hy"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# file_data=pd.read_csv('/content/drive/MyDrive/urdu_sarcastic_dataset.csv')"
      ],
      "metadata": {
        "id": "txdkKWqeDYoD"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# file_data.head()"
      ],
      "metadata": {
        "id": "NIA9voxREt5r"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for words in vocabulary:\n",
        "#   print(words)"
      ],
      "metadata": {
        "id": "wE8D20u7EwyX"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Tf(word,sentence):\n",
        "  count=0\n",
        "  words=sentence.split()\n",
        "  for w in words:\n",
        "    if w==word:\n",
        "      count+=1\n",
        "  return count/len(words)"
      ],
      "metadata": {
        "id": "mDIJFrjfFDnx"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Idf(word,corpus):\n",
        "  count=0\n",
        "  for sentence in corpus:\n",
        "    if word in sentence.split():\n",
        "      count+=1\n",
        "  return np.log(len(corpus)/count)"
      ],
      "metadata": {
        "id": "MaR0FbxnqSYu"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#maintain a dictinory for every word\n",
        "words_tfidf={}\n",
        "for word in vocabulary:\n",
        "  words_tfidf[word]=[]\n",
        "  for sentence in updated_corpus:\n",
        "    tf=Tf(word,sentence)\n",
        "    idf=Idf(word,updated_corpus)\n",
        "    words_tfidf[word].append(tf*idf)\n",
        "\n"
      ],
      "metadata": {
        "id": "EVEMhqPLKB5F"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(words_tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KywbO4TrjpNW",
        "outputId": "89aacc35-bdc1-4bc5-e3ce-c219cb94f4c4"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Ú©ØªØ§Ø¨': [0.2824326201290679, 0.0, 0.0, 0.0, 0.0, 0.16945957207744075, 0.16945957207744075], 'Ø¯Ù„Ú†Ø³Ù¾': [0.648636716351771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'Ù¾Ø³Ù†Ø¯': [0.648636716351771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'Ø²Ù†Ø¯Ú¯ÛŒ': [0.0, 0.38918202981106265, 0.0, 0.0, 0.0, 0.0, 0.0], 'Ú©Ø§Ù…ÛŒØ§Ø¨ÛŒ': [0.0, 0.2505525936990736, 0.0, 0.313190742123842, 0.0, 0.0, 0.0], 'Ù…Ø­Ù†Øª': [0.0, 0.2505525936990736, 0.0, 0.313190742123842, 0.0, 0.0, 0.0], 'ØµØ¨Ø±': [0.0, 0.38918202981106265, 0.0, 0.0, 0.0, 0.0, 0.0], 'Ø¶Ø±ÙˆØ±ÛŒ': [0.0, 0.38918202981106265, 0.0, 0.0, 0.0, 0.0, 0.0], 'Ú©Ø§Ù…': [0.0, 0.0, 0.9729550745276566, 0.0, 0.0, 0.0, 0.0], 'Ø®ØªÙ…': [0.0, 0.0, 0.9729550745276566, 0.0, 0.0, 0.0, 0.0], 'Ø­Ú©ÙˆÙ…Øª': [0.0, 0.0, 0.0, 0.4864775372638283, 0.0, 0.0, 0.0], 'Ø­Ø§ØµÙ„': [0.0, 0.0, 0.0, 0.4864775372638283, 0.0, 0.0, 0.0], 'Ø³ÛŒØ§Ø³Øª': [0.0, 0.0, 0.0, 0.0, 0.2505525936990736, 0.0, 0.2505525936990736], 'Ø¹ÙˆØ§Ù…': [0.0, 0.0, 0.0, 0.0, 0.38918202981106265, 0.0, 0.0], 'Ø³Ø®Øª': [0.0, 0.0, 0.0, 0.0, 0.38918202981106265, 0.0, 0.0], 'Ù‚Ø§Ù†ÙˆÙ†': [0.0, 0.0, 0.0, 0.0, 0.38918202981106265, 0.0, 0.0], 'Ø¨Ù†Ø§Ø¦Û’': [0.0, 0.0, 0.0, 0.0, 0.38918202981106265, 0.0, 0.0], 'Ø¨Ú†Û': [0.0, 0.0, 0.0, 0.0, 0.0, 0.38918202981106265, 0.0], 'Ø±ÙˆØ²Ø§Ù†Û': [0.0, 0.0, 0.0, 0.0, 0.0, 0.38918202981106265, 0.0], 'Ù¾Ú‘Ú¾Ù†Ø§': [0.0, 0.0, 0.0, 0.0, 0.0, 0.2505525936990736, 0.2505525936990736], 'Ú©Ø§Ù…ÛŒØ§Ø¨': [0.0, 0.0, 0.0, 0.0, 0.0, 0.38918202981106265, 0.0], 'Ø·Ù„Ø¨Ø§Ø¡': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38918202981106265], 'Ø¨Ø§Øª': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38918202981106265]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: i want to display top 10 words along with their tfidf from my words_tfidf dict\n",
        "\n",
        "# Iterate through the words_tfidf dictionary\n",
        "for word, tfidf_scores in words_tfidf.items():\n",
        "  # Calculate the average TF-IDF score for the word across all sentences\n",
        "  average_tfidf = sum(tfidf_scores) / len(tfidf_scores) if tfidf_scores else 0\n",
        "  # Store the word and its average TF-IDF score as a tuple\n",
        "  words_tfidf[word] = average_tfidf\n",
        "\n",
        "\n",
        "# Sort the dictionary by TF-IDF scores in descending order\n",
        "sorted_words_tfidf = dict(sorted(words_tfidf.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "# Get the top 10 words with their TF-IDF scores\n",
        "top_10_words = list(sorted_words_tfidf.items())[:10]\n",
        "\n",
        "# Print the top 10 words and their TF-IDF scores\n",
        "print(\"Top 10 words and their TF-IDF scores:\")\n",
        "for word, tfidf_score in top_10_words:\n",
        "    print(f\"{word}: {tfidf_score:.4f}\")\n"
      ],
      "metadata": {
        "id": "SJbFyViAk7RQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60172bb7-df5f-429b-f6bf-b6eed659e7c2"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 words and their TF-IDF scores:\n",
            "Ú©Ø§Ù…: 0.1390\n",
            "Ø®ØªÙ…: 0.1390\n",
            "Ø¯Ù„Ú†Ø³Ù¾: 0.0927\n",
            "Ù¾Ø³Ù†Ø¯: 0.0927\n",
            "Ú©ØªØ§Ø¨: 0.0888\n",
            "Ú©Ø§Ù…ÛŒØ§Ø¨ÛŒ: 0.0805\n",
            "Ù…Ø­Ù†Øª: 0.0805\n",
            "Ø³ÛŒØ§Ø³Øª: 0.0716\n",
            "Ù¾Ú‘Ú¾Ù†Ø§: 0.0716\n",
            "Ø­Ú©ÙˆÙ…Øª: 0.0695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G1xz_D_79X9f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}